import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import random

# Параметры модели

start = 0  # Первая точка входных данных, используемая моделью
count = 100  # Число точек, которые будет использовать модель (включая look_back)
forecast_length = 36  # Количество точек, которые нужно спрогнозировать
look_back = 35  # Количество предыдущих точек для прогнозирования
filters_1 = 32  # Количество фильтров в первом сверточном слое
kernel_size_1 = 3  # Размер ядра свертки в первом сверточном слое
filters_2 = 16  # Количество фильтров во втором сверточном слое
kernel_size_2 = 3  # Размер ядра свертки во втором сверточном слое
epochs = 200  # Количество эпох обучения
batch_size = 16  # Размер мини-пакета

# Фиксация начального состояния
seed = 7  # Начальное состояние для генераторов случайных чисел
np.random.seed(seed)
tf.random.set_seed(seed)
random.seed(seed)

# Временной ряд
data = np.array([
504.59, 523.09, 515.09, 521.59, 529.09, 530.09, 533.09, 530.09, 529.59, 517.59, 531.59, 528.59, 530.59, 532.59, 528.59, 527.09, 520.09, 513.09, 520.09, 516.09, 517.09, 517.59, 514.59, 522.24, 529.59, 525.24, 527.09, 531.09, 523.59, 529.09, 529.09, 530.09, 528.09, 534.24, 534.09, 530.59, 530.59, 520.09, 521.09, 523.09, 523.59, 517.59, 514.09, 505.09, 491.09, 489.59, 489.09, 493.09, 493.09, 495.59, 498.59, 496.59, 495.59, 492.59, 492.59, 488.59, 477.09, 467.59, 468.59, 474.59, 477.09, 473.09, 467.59, 461.59, 465.09, 472.59, 474.59, 467.09, 468.59, 474.09, 474.09, 473.59, 469.59, 485.59, 484.09, 484.09, 483.59, 483.59, 480.59, 483.59, 486.09, 484.09, 486.09, 482.59, 471.09, 472.59, 462.59, 503.09, 511.59, 517.59, 518.59, 518.09, 514.59, 518.09, 515.09, 512.59, 511.59, 511.09, 502.59, 503.59, 506.59, 504.09, 501.59, 496.59, 498.09, 494.09, 486.59, 489.59, 496.59, 502.59, 504.09, 500.09, 498.09, 494.59, 493.09, 497.09, 495.09, 488.09, 490.09, 493.09, 491.59, 491.09, 491.59, 492.09, 492.59, 495.09, 494.09, 492.09, 490.59, 492.09, 492.59, 495.09, 494.59, 510.09, 515.59, 516.59, 513.59, 516.59, 515.59, 515.59, 518.59, 516.09, 514.09, 514.09, 515.09, 515.09, 514.09, 517.09, 517.59, 520.59, 524.09, 532.59, 539.59, 531.59, 533.09, 534.59, 529.59, 529.59, 530.09, 536.09, 529.59, 534.09, 536.59, 526.59, 522.59, 519.09, 518.59, 519.09, 517.59, 522.59, 523.09, 524.09, 526.59, 520.09, 522.09, 520.59, 531.09, 536.09, 534.09, 535.59, 533.59, 533.59, 533.59, 531.59, 533.09, 534.09, 535.09, 537.09, 541.59, 540.09, 537.59, 539.59, 540.59, 538.59, 533.59, 532.59, 535.59, 534.59, 531.59, 529.59, 529.09, 526.59, 523.09, 523.09, 520.59, 522.59, 524.59, 524.59, 524.59, 523.59, 512.09, 514.59, 515.59, 513.59, 512.09, 511.09, 499.59, 494.09, 486.09, 489.59, 486.09, 477.59, 466.59, 474.09, 472.59, 476.09, 471.59, 477.09, 474.59, 461.59, 453.09, 453.59, 454.09, 449.59, 445.09, 449.59, 449.09, 447.09, 449.09, 447.09, 448.09, 448.59, 456.59, 463.59, 454.09, 457.59, 466.09, 464.09, 462.09, 462.59, 461.59, 458.09, 457.09, 458.59, 456.59, 452.09, 454.59, 457.09, 456.59, 456.09, 458.09, 454.09, 453.09, 449.09, 443.59, 449.09, 446.59, 448.59, 443.09, 444.59, 444.59, 444.09, 444.09, 436.59, 437.09, 439.09, 436.59, 428.09, 431.59, 430.09, 430.09, 425.59, 427.09, 431.09, 428.09, 429.59, 432.59, 435.59, 438.09, 432.59, 430.09, 429.59, 422.59, 429.59, 432.59, 432.09, 432.09, 434.59, 432.59, 436.59, 439.59, 440.09, 436.59, 434.59, 430.59, 431.09, 432.59, 431.59, 433.09, 433.59, 431.59, 430.59, 434.09, 435.09, 434.09, 435.59, 433.09, 434.59, 434.59, 434.59, 433.59, 432.09, 424.59, 418.09, 421.59, 418.59, 420.09, 419.09, 414.09, 416.09, 415.09, 414.09, 413.09, 415.59, 413.09, 408.09, 408.09, 406.59, 412.59, 412.09, 409.09, 410.09, 408.59, 407.09, 411.59, 450.09, 450.09, 450.09, 448.09, 449.59, 448.09, 444.59, 444.59, 445.59, 449.09, 448.09, 446.59, 447.59, 448.59, 447.09, 469.59, 469.09, 472.59, 470.09, 470.09, 473.59, 475.09, 473.09, 475.59, 474.59, 471.59, 471.59, 475.09, 477.59, 480.59, 479.09, 478.09, 478.09, 475.59, 474.59, 468.09, 471.59, 469.59, 466.59, 466.59, 466.59, 468.09, 465.59, 464.59, 467.59, 468.59, 460.09, 460.09, 454.59, 454.59, 456.09, 455.59, 456.59, 457.09, 458.59, 459.59, 462.59, 464.59, 462.59, 463.59, 468.59, 474.59, 474.59, 471.59, 470.59, 472.09, 471.59, 472.09, 472.59, 464.59, 465.09, 464.09, 471.09, 468.09, 468.59, 471.09, 469.59, 469.09, 470.09, 470.59, 473.09, 474.09, 471.09, 474.09, 469.09, 465.59, 469.59, 468.09, 466.09, 460.09, 461.09, 461.59, 465.09, 465.59, 464.59, 463.59, 467.59, 465.09, 465.09, 461.59, 454.59, 455.09, 457.59, 455.09, 460.09, 461.09, 468.59, 466.09, 465.59, 466.09, 465.59, 470.09, 468.59, 467.09, 466.59, 489.17, 484.67, 486.17, 482.17, 478.67, 481.17, 479.67, 478.67, 480.17, 482.67, 481.17, 479.17, 479.17, 481.17, 478.17, 480.67, 480.17, 478.17, 476.67, 474.67, 474.17, 475.17, 474.67, 475.67, 470.67, 470.17, 468.67, 457.67, 457.67, 461.67, 457.67, 456.17, 455.67, 455.17, 444.67, 447.17, 433.67, 434.17, 439.17, 439.17


])

# Проверка, что количество данных достаточно
if start + count > len(data):
    raise ValueError("Недостаточно данных для указанных start, count значений.")

# Выбор данных в соответствии с параметрами start и count
data_segment = data[start:start + count]

# Нормализация данных
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_segment.reshape(-1, 1)).flatten()

# Функция для создания временных окон
def create_dataset(series, look_back):
    X, y = [], []
    for i in range(len(series) - look_back):
        X.append(series[i:i + look_back])
        y.append(series[i + look_back])
    return np.array(X), np.array(y)

# Создание обучающего набора
X, y = create_dataset(data_scaled, look_back)

# Добавление дополнительного измерения для Conv1D
X = X[..., np.newaxis]

# Создание модели Causal CNN
model = Sequential([
    Conv1D(filters=filters_1, kernel_size=kernel_size_1, padding='causal', activation='relu', input_shape=(look_back, 1)),
    Conv1D(filters=filters_2, kernel_size=kernel_size_2, padding='causal', activation='relu'),
    Flatten(),
    Dense(1)
])

# Компиляция модели
model.compile(optimizer='adam', loss='mse')

# Обучение модели
model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=1)

# Прогнозирование следующих forecast_length значений
predictions = []
last_window = data_scaled[-look_back:].reshape(1, look_back, 1)

for _ in range(forecast_length):
    next_value_scaled = model.predict(last_window)
    predictions.append(next_value_scaled[0, 0])
    # Обновляем окно, добавляя предсказанное значение
    last_window = np.roll(last_window, -1)
    last_window[0, -1, 0] = next_value_scaled

# Обратное преобразование прогноза в исходный масштаб
predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()

# Реальные значения для сравнения
real_values = data[start + count:start + count + forecast_length]

# Визуализация результатов
plt.figure(figsize=(12, 6))
plt.plot(range(start, start + count), data_segment, label='Исходный временной ряд')
plt.plot(range(start + count, start + count + forecast_length), real_values, label='Реальные значения')
plt.plot(range(start + count, start + count + forecast_length), predictions, label='Прогноз', linestyle='--')
plt.title('Прогнозирование временного ряда с использованием модели C')
plt.xlabel('Временные точки')
plt.ylabel('Значения')
plt.legend()
plt.show()

